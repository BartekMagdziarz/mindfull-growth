Story 4 – System Prompts & Chat Intentions

Goal

Define the system prompts for each chat intention and create the logic for constructing context messages from journal entry data. This story establishes the core behavior and personality of the LLM for each chat intention, ensuring that conversations are therapeutic, supportive, and aligned with the app's goal of helping users gain insights from their journaling practice.

⸻

Scope

	1.	System Prompts Configuration
	•	Create a new configuration module: `src/services/chatPrompts.ts` (or `src/utils/chatPrompts.ts`)
	•	Define system prompts for each of the five chat intentions:
	•	"Reflect" – Help the user reflect on their entry, explore deeper meanings, and understand their emotional patterns.
	•	"Help see differently" – Guide the user to consider alternative perspectives and challenge assumptions.
	•	"Help to be proactive" – Assist the user in identifying actionable steps and proactive solutions.
	•	"Thinking traps" – Help identify cognitive distortions and unhelpful thinking patterns.
	•	"Custom" – Use the user-provided custom prompt as the system prompt.
	•	Each system prompt should:
	•	Set the LLM's role and conversation style (therapeutic, supportive, non-judgmental).
	•	Instruct the LLM to use the journal entry's title, body, emotions, and tags as context.
	•	Encourage concise conversations (3-5 exchanges recommended).
	•	Ask thoughtful, open-ended questions when appropriate.
	•	Be empathetic and non-judgmental.
	•	Respect user privacy and avoid making clinical diagnoses.
	•	Structure:
	•	Create a function `getSystemPrompt(intention: ChatIntention, customPrompt?: string): string`
	•	This function takes the intention type and optional custom prompt, and returns the appropriate system prompt string.
	•	For "custom" intention, return the customPrompt if provided, otherwise return a default custom prompt.
	•	Export the function and any constants needed.
	•	Consider creating a type-safe mapping object:
	•	```typescript
	•	const SYSTEM_PROMPTS: Record<ChatIntention, string> = {
	•	  "reflect": "...",
	•	  "help-see-differently": "...",
	•	  "proactive": "...",
	•	  "thinking-traps": "...",
	•	  "custom": "..." // This will be overridden by customPrompt
	•	}
	•	```
	•	Prompt Design Guidelines:
	•	Each prompt should be 2-4 sentences, clear and focused.
	•	Use second person ("you") to address the LLM directly.
	•	Include specific instructions about the conversation style and goals.
	•	Reference the journal entry context explicitly.
	•	Example structure for each prompt:
	•	Role definition (what is the LLM's role)
	•	Context usage (how to use the journal entry data)
	•	Conversation style (how to interact)
	•	Boundaries (what not to do)

	2.	Context Message Construction
	•	Create a function to construct the initial context message from journal entry data:
	•	Function: `constructJournalEntryContext(entry: JournalEntry, emotionStore: EmotionStore, tagStore: TagStore): string`
	•	This function takes:
	•	A JournalEntry object (with title, body, emotionIds, peopleTagIds, contextTagIds)
	•	References to emotion and tag stores (or repositories) to resolve IDs to names
	•	Returns a formatted string containing:
	•	Entry title (or "Untitled entry" if empty)
	•	Selected emotions (resolved from IDs to emotion names)
	•	Selected tags (resolved from IDs to tag names, separated by people and context)
	•	Entry body (full text)
	•	Format the context message in a clear, readable way for the LLM:
	•	Example format:
	•	"Journal Entry Context:
	•	Title: [title or "Untitled entry"]
	•	Emotions: [emotion1, emotion2, ...] (or "None" if empty)
	•	People Tags: [tag1, tag2, ...] (or "None" if empty)
	•	Context Tags: [tag1, tag2, ...] (or "None" if empty)
	•	Content:
	•	[entry body text]"
	•	Handle edge cases:
	•	Empty title: Use "Untitled entry"
	•	Empty emotions: Show "None" or empty list
	•	Empty tags: Show "None" or empty list for each category
	•	Empty body: Should not happen (Chat button is disabled if body is empty), but handle gracefully
	•	Very long entries: For MVP, include full entry. Document that truncation can be added in the future if needed.
	•	ID Resolution:
	•	Use the emotion store to resolve emotionIds to emotion names
	•	Use the tag store to resolve peopleTagIds and contextTagIds to tag names
	•	Handle cases where IDs don't exist (shouldn't happen in normal flow, but handle gracefully)
	•	Consider creating a helper function for resolving IDs to names if the logic becomes complex

	3.	Integration with Chat Store
	•	Update the chat store (from Story 3) to use the new prompt functions:
	•	Import `getSystemPrompt` from the prompts module
	•	In the `sendMessage` action, replace the placeholder system prompt with:
	•	`const systemPrompt = getSystemPrompt(currentChatSession.intention, currentChatSession.customPrompt)`
	•	Import `constructJournalEntryContext` from the prompts module
	•	In the `sendMessage` action, replace the placeholder context construction with:
	•	`const contextMessage = constructJournalEntryContext(entry, emotionStore, tagStore)`
	•	Ensure the chat store properly passes the emotion and tag stores to the context construction function
	•	Note: This integration should be straightforward since Story 3 already has placeholders for these functions

	4.	Prompt Content Design
	•	Design the actual prompt text for each intention:
	•	"Reflect" Prompt:
	•	Focus on helping the user explore deeper meanings, understand patterns, and gain self-awareness.
	•	Encourage reflection on emotions, thoughts, and behaviors.
	•	Ask questions that help the user understand themselves better.
	•	Example: "You are a supportive reflection guide helping the user explore their journal entry. Use the entry's title, content, emotions, and tags to help them understand deeper meanings, recognize patterns in their thoughts and feelings, and gain self-awareness. Ask thoughtful, open-ended questions that encourage reflection. Keep conversations concise (3-5 exchanges). Be empathetic and non-judgmental. Do not make clinical diagnoses."
	•	"Help see differently" Prompt:
	•	Focus on helping the user consider alternative perspectives and challenge assumptions.
	•	Encourage cognitive flexibility and reframing.
	•	Help the user see situations from different angles.
	•	Example: "You are a perspective-shifting guide helping the user see their journal entry from different angles. Use the entry's context to gently challenge assumptions, suggest alternative viewpoints, and help them reframe their thinking. Ask questions that open up new possibilities. Keep conversations concise (3-5 exchanges). Be supportive and non-judgmental. Do not make clinical diagnoses."
	•	"Help to be proactive" Prompt:
	•	Focus on helping the user identify actionable steps and proactive solutions.
	•	Encourage forward-thinking and problem-solving.
	•	Help the user move from reflection to action.
	•	Example: "You are a proactive planning assistant helping the user identify actionable steps based on their journal entry. Use the entry's context to help them move from reflection to action, identify concrete steps they can take, and develop proactive solutions. Ask questions that help them think about what they can do. Keep conversations concise (3-5 exchanges). Be encouraging and supportive. Do not make clinical diagnoses."
	•	"Thinking traps" Prompt:
	•	Focus on helping the user identify cognitive distortions and unhelpful thinking patterns.
	•	Educate about common thinking traps (e.g., all-or-nothing thinking, catastrophizing, overgeneralization).
	•	Help the user recognize and reframe distorted thinking.
	•	Example: "You are a cognitive awareness guide helping the user identify unhelpful thinking patterns in their journal entry. Use the entry's context to gently point out potential cognitive distortions (like all-or-nothing thinking, catastrophizing, or overgeneralization) and help them reframe these thoughts. Ask questions that help them recognize thinking traps. Keep conversations concise (3-5 exchanges). Be educational and supportive, not critical. Do not make clinical diagnoses."
	•	"Custom" Prompt:
	•	Use the user-provided custom prompt as-is, or provide a default if none is given.
	•	Default custom prompt should be neutral and flexible.
	•	Example default: "You are a supportive assistant helping the user explore their journal entry. Use the entry's context to have a helpful conversation based on the user's specific needs. Keep conversations concise (3-5 exchanges). Be empathetic and non-judgmental. Do not make clinical diagnoses."
	•	Note: The actual prompt text should be refined based on testing and user feedback, but these examples provide a good starting point.

	5.	Type Safety & Constants
	•	Ensure type safety throughout:
	•	Import ChatIntention type from `src/domain/chatSession.ts`
	•	Use TypeScript's type system to ensure only valid intentions are used
	•	Consider exporting a constant object with intention values for consistency:
	•	```typescript
	•	export const CHAT_INTENTIONS = {
	•	  REFLECT: "reflect",
	•	  HELP_SEE_DIFFERENTLY: "help-see-differently",
	•	  PROACTIVE: "proactive",
	•	  THINKING_TRAPS: "thinking-traps",
	•	  CUSTOM: "custom"
	•	} as const
	•	```
	•	This ensures consistency across the codebase and makes refactoring easier
	•	Export types and constants for use in other modules

	6.	Unit Tests
	•	Add comprehensive unit tests (Vitest) for:
	•	System Prompt Function:
	•	Test `getSystemPrompt` with each valid intention:
	•	Test "reflect" returns the reflect prompt
	•	Test "help-see-differently" returns the help-see-differently prompt
	•	Test "proactive" returns the proactive prompt
	•	Test "thinking-traps" returns the thinking-traps prompt
	•	Test "custom" with customPrompt parameter returns the custom prompt
	•	Test "custom" without customPrompt parameter returns the default custom prompt
	•	Test that prompts are non-empty strings
	•	Test that prompts contain expected keywords (e.g., "journal entry", "empathetic")
	•	Context Message Construction:
	•	Test `constructJournalEntryContext` with various entry configurations:
	•	Entry with title, body, emotions, and tags (happy path)
	•	Entry with empty title (should use "Untitled entry")
	•	Entry with no emotions (should show "None" or empty)
	•	Entry with no tags (should show "None" or empty for each category)
	•	Entry with only people tags (context tags should show "None")
	•	Entry with only context tags (people tags should show "None")
	•	Entry with very long body (should include full body)
	•	Test ID resolution:
	•	Mock emotion store to return emotion names for given IDs
	•	Mock tag store to return tag names for given IDs
	•	Test that non-existent IDs are handled gracefully
	•	Test that the context message format is correct (contains title, emotions, tags, content sections)
	•	Test that the context message is properly formatted and readable
	•	Edge Cases:
	•	Test with null or undefined entry (should throw error or handle gracefully)
	•	Test with entry that has null/undefined fields (should handle gracefully)
	•	Test with empty entry body (should handle gracefully, though this shouldn't happen in normal flow)
	•	Integration:
	•	Test that the functions work correctly when imported into the chat store (if possible without full store setup)
	•	Use mocking for:
	•	Emotion store (mock getEmotionById or similar methods)
	•	Tag store (mock getTagById or similar methods)
	•	Follow existing test patterns in the codebase
	•	Use descriptive test names
	•	Test both happy paths and edge cases

⸻

Acceptance Criteria

	•	System Prompts Configuration:
	•	`src/services/chatPrompts.ts` (or `src/utils/chatPrompts.ts`) file exists with `getSystemPrompt` function defined.
	•	Function accepts ChatIntention type and optional customPrompt parameter.
	•	Function returns appropriate system prompt string for each intention:
	•	"reflect" returns the reflect prompt
	•	"help-see-differently" returns the help-see-differently prompt
	•	"proactive" returns the proactive prompt
	•	"thinking-traps" returns the thinking-traps prompt
	•	"custom" with customPrompt returns the provided custom prompt
	•	"custom" without customPrompt returns a default custom prompt
	•	All prompts are non-empty strings.
	•	All prompts follow the design guidelines (therapeutic, supportive, non-judgmental, reference journal entry context).
	•	Context Message Construction:
	•	`constructJournalEntryContext` function exists and accepts JournalEntry, emotion store, and tag store.
	•	Function returns a formatted string containing:
	•	Entry title (or "Untitled entry" if empty)
	•	Selected emotions (resolved from IDs to names, or "None" if empty)
	•	Selected people tags (resolved from IDs to names, or "None" if empty)
	•	Selected context tags (resolved from IDs to names, or "None" if empty)
	•	Entry body (full text)
	•	Function handles edge cases gracefully (empty fields, missing IDs, etc.).
	•	Context message format is clear and readable for the LLM.
	•	Integration with Chat Store:
	•	Chat store imports and uses `getSystemPrompt` function.
	•	Chat store imports and uses `constructJournalEntryContext` function.
	•	Chat store replaces placeholder prompts with actual prompt functions.
	•	Chat store correctly passes parameters to prompt functions.
	•	Type Safety:
	•	All functions use proper TypeScript types (ChatIntention, JournalEntry, etc.).
	•	Constants are exported for intention values (if implemented).
	•	Types are properly imported from domain models.
	•	The app can be started and:
	•	Prompt functions can be imported and used.
	•	Prompt functions return correct prompts for each intention.
	•	Context construction function works with real journal entries.
	•	Chat store can use the prompt functions (though full chat flow won't work until UI is built).
	•	Unit tests for prompt functions pass.
	•	Unit tests for context construction pass.
	•	Linting and TypeScript checks pass with no new errors.

⸻

Out of Scope

	•	Chat UI components (will be implemented in Stories 6 and 7).
	•	Chat store implementation (already implemented in Story 3, this story just updates it to use real prompts).
	•	Streaming responses from LLM (will be added in a future story).
	•	Dynamic prompt customization based on user preferences (out of scope for this epic).
	•	Prompt templates or saved custom prompts (out of scope for this epic).
	•	Multi-language prompt support (only English for this epic).
	•	Prompt versioning or A/B testing (out of scope for this epic).
	•	Context message truncation for very long entries (full entry included for MVP, can be optimized later).
	•	Advanced context formatting (beyond basic text format, can be enhanced in future).

⸻

Technical Considerations

	•	Prompt Design Philosophy:
	•	Prompts should be therapeutic but not clinical. They should guide, not diagnose.
	•	Prompts should encourage self-discovery rather than providing direct advice.
	•	Prompts should be concise enough to fit within token limits while being clear about expectations.
	•	Prompts should be tested with real journal entries to ensure they produce helpful conversations.
	•	Context Message Format:
	•	The context message format should be clear and structured for the LLM to parse easily.
	•	Consider using clear section headers (Title:, Emotions:, etc.) to help the LLM understand the structure.
	•	The format should be consistent across all entries to help the LLM learn the pattern.
	•	Token Limits:
	•	For MVP, include the full journal entry in the context. Most entries will be within token limits.
	•	Document that truncation can be added in the future if needed for very long entries.
	•	Consider the total token count: system prompt + context message + conversation history + new message.
	•	OpenAI's gpt-4o-mini has a context window, so very long entries + long conversations might hit limits (but this is unlikely for MVP use cases).
	•	Store Integration:
	•	The context construction function needs access to emotion and tag stores to resolve IDs to names.
	•	Consider passing stores as parameters (as specified) or using dependency injection.
	•	Alternatively, the function could accept resolved names directly, but passing stores is more flexible.
	•	Type Safety:
	•	Use TypeScript's type system to ensure only valid intentions are passed to `getSystemPrompt`.
	•	Consider using const assertions for intention values to ensure type safety.
	•	File Organization:
	•	Decide whether prompts belong in `src/services/` (alongside llmService) or `src/utils/` (utility functions).
	•	Recommendation: `src/services/chatPrompts.ts` since it's closely related to the LLM service and chat functionality.
	•	Testing Strategy:
	•	Mock stores in tests to avoid dependencies on real store implementations.
	•	Test prompt content to ensure it meets design guidelines (contains key phrases, is non-empty, etc.).
	•	Test context construction with various entry configurations to ensure robustness.
	•	Consider snapshot testing for prompts (to detect unintended changes) if the team uses snapshot testing.

⸻

Implementation Notes

	•	Prompt Module Structure:
	•	```typescript
	•	import type { ChatIntention } from '@/domain/chatSession'
	•	import type { JournalEntry } from '@/domain/journal'
	•	
	•	export const CHAT_INTENTIONS = {
	•	  REFLECT: "reflect",
	•	  HELP_SEE_DIFFERENTLY: "help-see-differently",
	•	  PROACTIVE: "proactive",
	•	  THINKING_TRAPS: "thinking-traps",
	•	  CUSTOM: "custom"
	•	} as const
	•	
	•	const SYSTEM_PROMPTS: Record<Exclude<ChatIntention, "custom">, string> = {
	•	  "reflect": "You are a supportive reflection guide...",
	•	  "help-see-differently": "You are a perspective-shifting guide...",
	•	  "proactive": "You are a proactive planning assistant...",
	•	  "thinking-traps": "You are a cognitive awareness guide..."
	•	}
	•	
	•	const DEFAULT_CUSTOM_PROMPT = "You are a supportive assistant..."
	•	
	•	export function getSystemPrompt(intention: ChatIntention, customPrompt?: string): string {
	•	  if (intention === "custom") {
	•	    return customPrompt || DEFAULT_CUSTOM_PROMPT
	•	  }
	•	  return SYSTEM_PROMPTS[intention]
	•	}
	•	
	•	export function constructJournalEntryContext(
	•	  entry: JournalEntry,
	•	  emotionStore: any, // Use proper type from emotion store
	•	  tagStore: any // Use proper type from tag store
	•	): string {
	•	  // Implementation
	•	}
	•	```
	•	Context Construction Implementation:
	•	```typescript
	•	export function constructJournalEntryContext(
	•	  entry: JournalEntry,
	•	  emotionStore: EmotionStore,
	•	  tagStore: TagStore
	•	): string {
	•	  const title = entry.title || "Untitled entry"
	•	  
	•	  // Resolve emotions
	•	  const emotions = entry.emotionIds
	•	    ?.map(id => emotionStore.getEmotionById(id)?.name)
	•	    .filter(Boolean)
	•	    .join(", ") || "None"
	•	  
	•	  // Resolve people tags
	•	  const peopleTags = entry.peopleTagIds
	•	    ?.map(id => tagStore.getTagById(id)?.name)
	•	    .filter(Boolean)
	•	    .join(", ") || "None"
	•	  
	•	  // Resolve context tags
	•	  const contextTags = entry.contextTagIds
	•	    ?.map(id => tagStore.getTagById(id)?.name)
	•	    .filter(Boolean)
	•	    .join(", ") || "None"
	•	  
	•	  return `Journal Entry Context:
	•	Title: ${title}
	•	Emotions: ${emotions}
	•	People Tags: ${peopleTags}
	•	Context Tags: ${contextTags}
	•	Content:
	•	${entry.body}`
	•	}
	•	```
	•	Note: The actual implementation may vary based on how the emotion and tag stores are structured. Adjust the code to match the actual store API.
	•	Chat Store Integration:
	•	In `src/stores/chat.store.ts`, update the `sendMessage` action:
	•	```typescript
	•	import { getSystemPrompt, constructJournalEntryContext } from '@/services/chatPrompts'
	•	import { useEmotionStore } from './emotion.store'
	•	import { useTagStore } from './tag.store'
	•	
	•	// In sendMessage action:
	•	const emotionStore = useEmotionStore()
	•	const tagStore = useTagStore()
	•	const systemPrompt = getSystemPrompt(
	•	  currentChatSession.value.intention,
	•	  currentChatSession.value.customPrompt
	•	)
	•	const contextMessage = constructJournalEntryContext(entry, emotionStore, tagStore)
	•	```
	•	File Organization:
	•	Prompt file: `src/services/chatPrompts.ts`
	•	Test file: `src/services/__tests__/chatPrompts.spec.ts`
	•	Follow existing naming conventions and file structure.
	•	Dependencies:
	•	Import types from domain models (ChatIntention from chatSession.ts, JournalEntry from journal.ts).
	•	Import store types (or use `any` temporarily if store types aren't available yet).
	•	Testing:
	•	Create comprehensive test file with mocked stores.
	•	Use Vitest's `vi.mock` to mock emotion and tag stores.
	•	Test each prompt intention thoroughly.
	•	Test context construction with various entry configurations.
	•	Follow existing test patterns in the codebase.

