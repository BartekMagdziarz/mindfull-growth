Story 1 – API Key Management & LLM Service Foundation

Goal

Add API key management functionality to the Profile view and create the foundational LLM service module that will handle communication with the OpenAI API. This story establishes the infrastructure needed for all chat functionality, including secure storage of the API key, basic OpenAI API integration, and robust error handling.

⸻

Scope

	1.	API Key Storage Mechanism
	•	Create a storage mechanism for the OpenAI API key using IndexedDB (via Dexie).
	•	Extend the existing MindfullGrowthDatabase class (from journalDexieRepository.ts) to include:
	•	A new table for user settings (e.g., `userSettings` table).
	•	The table should store key-value pairs for user preferences and settings.
	•	Schema structure:
	•	key: string (primary key, e.g., "openaiApiKey")
	•	value: string (the actual API key value)
	•	Increment database version appropriately (e.g., from version 3 to version 4).
	•	Create a repository interface and implementation for user settings:
	•	Interface: `UserSettingsRepository` in `src/repositories/userSettingsRepository.ts`
	•	Methods:
	•	`get(key: string): Promise<string | undefined>` – retrieves a setting value by key
	•	`set(key: string, value: string): Promise<void>` – sets a setting value
	•	`delete(key: string): Promise<void>` – deletes a setting
	•	Implementation: `userSettingsDexieRepository.ts` using the shared database instance.
	•	Error handling: If IndexedDB fails, throw errors that can be caught gracefully.
	•	Note: For MVP, storing the API key in IndexedDB is acceptable. Security considerations should be documented (see Technical Considerations section).

	2.	Profile View – API Key Input Section
	•	Update ProfileView.vue to include an "AI Settings" or "LLM Configuration" section:
	•	Add a new AppCard component for the AI Settings section.
	•	Within the card, include:
	•	Section title: "AI Settings" or "LLM Configuration"
	•	Input field for OpenAI API key:
	•	Label: "OpenAI API Key"
	•	Type: password (masked input for security, using HTML input type="password").
	•	Placeholder: "sk-..." or "Enter your OpenAI API key"
	•	Help text: Brief explanation of why the API key is needed and how to obtain one.
	•	Include a link to OpenAI's website (https://platform.openai.com/api-keys) where users can create an API key.
	•	Help text should be styled as secondary text (text-on-surface-variant).
	•	Current model display: Show "Model: gpt-4o-mini" (read-only, with a note that this can be changed in the future).
	•	"Save" button:
	•	Uses AppButton component with "filled" variant.
	•	Disabled state: Button should be disabled if the API key input is empty or invalid (based on validation).
	•	Loading state: Show loading indicator while saving.
	•	Success feedback: Show a snackbar or success message when the API key is saved successfully.
	•	Validation:
	•	Real-time validation: As the user types, validate the API key format.
	•	Format validation: API key should start with "sk-" (case-sensitive).
	•	Show validation error message below the input if format is invalid (e.g., "API key must start with 'sk-'").
	•	Visual feedback: Use error styling (e.g., red border) when validation fails.
	•	UI consistency:
	•	Use existing Material Design–inspired components (AppCard, AppButton).
	•	Follow the same color scheme, spacing, and typography as the rest of the app.
	•	Ensure the layout is responsive and accessible.

	3.	LLM Service Module
	•	Create a new service module for LLM communication: `src/services/llmService.ts` (or `src/services/openaiService.ts`).
	•	Responsibilities:
	•	API key retrieval: Get the API key from user settings storage.
	•	API request construction: Build the request payload for OpenAI API calls.
	•	API communication: Send HTTP requests to OpenAI's API endpoint.
	•	Response handling: Parse and return the API response.
	•	Error handling: Handle various error scenarios gracefully.
	•	Core functionality:
	•	`sendMessage(messages: Array<{role: "user" | "assistant" | "system", content: string}>, systemPrompt?: string): Promise<string>`
	•	Constructs the request payload with:
	•	Model: "gpt-4o-mini" (default, configurable in the future).
	•	Messages array: Includes system prompt (if provided) and conversation messages.
	•	Temperature: 0.7 (default, can be made configurable later).
	•	Max tokens: 500 (default, can be adjusted based on needs).
	•	Sends POST request to OpenAI API endpoint: `https://api.openai.com/v1/chat/completions`
	•	Uses the API key from storage in the Authorization header: `Bearer ${apiKey}`
	•	Returns the assistant's message content from the response.
	•	Error handling:
	•	Missing API key: Throw a clear error (e.g., "OpenAI API key is not configured. Please add your API key in Profile settings.").
	•	Invalid API key: Handle 401 Unauthorized response with user-friendly message.
	•	Rate limit errors: Handle 429 Too Many Requests with helpful message.
	•	Network errors: Handle connection failures with retry guidance.
	•	API errors: Parse OpenAI error responses and provide meaningful messages.
	•	Log errors for debugging (without exposing sensitive data like the API key).
	•	Note: Start with non-streaming responses for simplicity. Streaming can be added in a future story.

	4.	API Key Validation & Testing
	•	Implement API key validation logic:
	•	Format validation: Check that the key starts with "sk-" (basic format check).
	•	Optional: Test API key validity by making a simple API call when the user saves the key.
	•	If testing is implemented:
	•	Make a minimal API call (e.g., send a simple system message) to verify the key works.
	•	Show success message if the key is valid.
	•	Show error message if the key is invalid or the API call fails.
	•	This validation should be optional (not blocking) – users can save the key even if the test fails (in case of network issues).
	•	Store validation result (valid/invalid) but don't prevent saving.

	5.	Pinia Store for User Settings (Optional)
	•	Consider creating a Pinia store for user settings management:
	•	Store name: `useUserSettingsStore` in `src/stores/userSettings.store.ts`
	•	State:
	•	settings: Record<string, string> (key-value pairs)
	•	isLoading: boolean
	•	error: string | null
	•	Actions:
	•	`loadSettings()`: Load all settings from the repository.
	•	`getSetting(key: string)`: Get a specific setting value.
	•	`setSetting(key: string, value: string)`: Set a setting value and persist to repository.
	•	`deleteSetting(key: string)`: Delete a setting.
	•	Rationale: Centralized state management for settings, makes it easier to access settings across the app.
	•	Note: This is optional for Story 1. The ProfileView can directly use the repository if preferred. The store can be added later if needed.

	6.	Unit Tests
	•	Add comprehensive unit tests (Vitest) for:
	•	LLM Service:
	•	API request construction: Verify the request payload is correctly formatted.
	•	API key retrieval: Test that the service retrieves the API key from storage.
	•	Successful API call: Mock successful OpenAI API response and verify the service returns the message content.
	•	Error handling: Test various error scenarios:
	•	Missing API key
	•	Invalid API key (401 response)
	•	Rate limit errors (429 response)
	•	Network errors
	•	Malformed API responses
	•	Use mocking for HTTP requests (e.g., `vi.mock` with fetch or axios).
	•	User Settings Repository:
	•	Setting and getting values
	•	Deleting values
	•	Error handling for IndexedDB failures
	•	API Key Validation:
	•	Format validation (starts with "sk-")
	•	Invalid format handling
	•	Use mocked repository implementations for tests (no need to hit real IndexedDB or OpenAI API in unit tests).

⸻

Acceptance Criteria

	•	User Settings Repository:
	•	Interface and implementation exist for storing and retrieving user settings.
	•	Database schema is updated to include userSettings table.
	•	Repository can get, set, and delete settings successfully.
	•	Profile View:
	•	Displays an "AI Settings" section with API key input field.
	•	API key input is masked (password type).
	•	Help text explains how to obtain an API key and includes a link to OpenAI's website.
	•	Current model (gpt-4o-mini) is displayed.
	•	"Save" button is present and functional.
	•	API key format validation works (shows error if key doesn't start with "sk-").
	•	Save button is disabled when API key is empty or invalid.
	•	Success feedback is shown when API key is saved.
	•	API key is persisted to IndexedDB when saved.
	•	LLM Service:
	•	Service module exists and can send messages to OpenAI API.
	•	Service retrieves API key from storage automatically.
	•	Service constructs correct API request payload (model, messages, temperature, max_tokens).
	•	Service handles successful API responses and returns message content.
	•	Service handles errors gracefully:
	•	Missing API key: Clear error message.
	•	Invalid API key (401): User-friendly error message.
	•	Rate limit (429): Helpful error message.
	•	Network errors: Appropriate error handling.
	•	Errors are logged for debugging (without exposing sensitive data).
	•	The app can be started and:
	•	Profile view displays the AI Settings section without errors.
	•	Users can enter and save an API key.
	•	API key is stored in IndexedDB and persists across page refreshes.
	•	LLM service can be imported and used (though it won't be called from UI until later stories).
	•	Unit tests for LLM service pass.
	•	Unit tests for user settings repository pass.
	•	Linting and TypeScript checks pass with no new errors.

⸻

Out of Scope

	•	Streaming responses from the LLM (will be added in a future story).
	•	Multiple LLM providers (only OpenAI for this epic).
	•	API key encryption (for MVP, storing in IndexedDB is acceptable; encryption can be added later).
	•	Advanced rate limiting UI or retry logic (beyond basic error messages).
	•	API key rotation or expiration handling.
	•	Usage analytics or token counting.
	•	Chat UI components (will be implemented in later stories).
	•	System prompts or chat intentions (will be implemented in Story 4).
	•	Integration with journal entries (will be implemented in later stories).

⸻

Technical Considerations

	•	API Key Security:
	•	For MVP, storing the API key in IndexedDB is acceptable, but document security considerations.
	•	Note: IndexedDB is more secure than localStorage (not accessible via XSS in the same way), but still stored locally in the browser.
	•	In production, consider:
	•	Encrypting the API key before storage (using Web Crypto API).
	•	Using a secure storage solution or backend proxy for API keys.
	•	Warning users about the security implications of storing API keys locally.
	•	API Key Format:
	•	OpenAI API keys start with "sk-" followed by alphanumeric characters.
	•	Basic format validation is sufficient for MVP (checking for "sk-" prefix).
	•	Full validation would require making an API call, which is optional for this story.
	•	Error Messages:
	•	All error messages should be user-friendly and actionable.
	•	Avoid exposing technical details or stack traces to users.
	•	Log detailed errors to the console for debugging purposes.
	•	Database Migration:
	•	When adding the userSettings table, ensure the migration handles existing databases gracefully.
	•	Existing data should not be lost when the database version is incremented.
	•	Testing Strategy:
	•	Use mocking extensively in unit tests to avoid making real API calls.
	•	Mock the fetch API or HTTP client used for OpenAI API calls.
	•	Mock the user settings repository to avoid hitting real IndexedDB in tests.
	•	Consider adding integration tests in later stories that test the full flow with a test API key.

⸻

Implementation Notes

	•	Database Schema Update:
	•	The userSettings table should use a simple key-value structure.
	•	Key: string (primary key)
	•	Value: string (the setting value)
	•	This allows for future extensibility (other settings can be stored in the same table).
	•	LLM Service Structure:
	•	The service should be a simple module with exported functions, not a class (to keep it functional and easy to test).
	•	Example structure:
	•	`getApiKey(): Promise<string | null>` – retrieves API key from storage
	•	`sendMessage(messages, systemPrompt?): Promise<string>` – main function for sending messages
	•	Error types: Define custom error classes or use error codes for different error scenarios.
	•	Profile View Implementation:
	•	Use Vue 3 Composition API with `<script setup>`.
	•	Use reactive state for form input and validation.
	•	Use computed properties for button disabled state based on validation.
	•	Consider using a form validation library if the app already uses one, otherwise implement simple validation manually.

